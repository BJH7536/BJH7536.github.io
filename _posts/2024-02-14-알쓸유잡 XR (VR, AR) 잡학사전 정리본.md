---
title:  알쓸유잡 🥽XR (VR / AR) 잡학사전 정리본
date:   2024-02-14 +0900
categories: [Unity]
tags: [Unity, XR, VR, AR]
math: true
mermaid: true
---


> [알쓸유잡 : 🥽XR (VR / AR) 잡학사전](https://www.youtube.com/watch?v=jOKkg3s9D4s&list=PL412Ym60h6ut9NcbAIfzVgyy5F4O22oSq&index=16&ab_channel=UnityKorea)

> 본 글은 위 영상을 참고하여 만든 정리본임.

---

## XR/VR/AR/MR

- VR (Virtual Reality) : 가상현실
    - 앞이 꽉 막힌 HMD
- AR (Augmented Reality) : 증강현실
    - 현실 위에 가상의 공간과 물체를 겹쳐 보여줌
- MR (Mixed Reality) : 혼합현실
    - 현실과 가상이 적절히 혼합된 형태 (명확 X, 모호)
- XR (eXtended Reality) : 확장현실
    - 위 모든 것을 포함하는 개념

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/0796fe18-2216-4087-b624-5862d73093df)

각기 다른 회사에서 만든 제품에 대한 홍보 영상의 일부. 얼핏보면 모두 같은 제품에 대한 광고로 보일 정도로 유사해보인다. 결국 모든 회사가 추구하는 건 XR?

[_흥미로워 보이는 앱 Deskucchi_](https://www.meta.com/ko-kr/experiences/5872942456118694/) 

## Pass-through VS See-through

- MR 환경 구축을 위한 디바이스의 두가지 타입

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/d6c90cd4-e24a-40f3-975b-733d42703c24) {: w="700" h="400" }

- **See-through**
    - 광학적인 방식으로 실제 현실을 보는 것.
    - 장비 내부의 projector가 현실위에 가상 물체를 겹쳐 보여준다.
    - 광학 장비가 많이 들어가다보니, 부피가 커지는 경향
    - AR 글래스 타입의 장비가 사용하는 방식
    - **[단점]**
        - **시야각 이슈**
            - 생각보다 시야각이 좁다.
        - **밝기 이슈**
            - 외부 현실에, 광학 렌더링한 결과를 덧씌우는 방식(가산 연산)으로 인해 그림자와 같은 어두움을 표현하기 어려움.
            - 햇빛이 밝은 야외에서는 사용하기 어려움. 사용 가능 범위가 실내로 제한되는 경향이 존재.
        - **색감 이슈**
            - 동일한 색이 시야상의 위치에 따라 다르게 보인다.
        - **폼팩터 이슈**
            - 글래스형 장비치고는, 흉…한 외관을 가지는 사례가 있다.
- **Pass-through**
    - 카메라를 통해 장비 외부의 현실 영상을 실시간으로 인식하고,
        - 가상의 물체를 렌더링한 결과와 혼합해 Display.
    - 외부를 간접적으로 보는 방식
    - VR 장비가 사용하는 방식
    - **[단점]**
        - **다이나믹 레인지**
            - 인간의 눈으로 인식할 수 있는 색 범위보다 카메라가 인식 가능한 범위가 더 좁기 때문에 발생하는 현상.
            - 이렇게 수신한 현실에 대한 영상을 실제 눈으로 보면 좀 어색하겠지?
        - **해상도 & 주사율**
            - 인간의 눈으로 인식하는 현실에 대한 정보는 장비에 비해 매우 고성능이다. (굳이 따지자면) 그래서 이를 장비로 대체했을 때, 장비가 눈의 성능을 따라오지 못해 나타나는 어색함을 사실 어쩔 수 없는 것 아닐까.

## 입체시 & 양안 시차

- 입체시 Stereoscopic 3D view
- 양안 시차 Binocular Parallax

사람이 입체감을 느끼는 이유는 눈이 두개이기 때문이다. 두 개의 눈으로 인식하는 영상은 정확히 동일한 영상이 아니다. (양안 시차) 두 눈의 위치가 다르기 때문. 바로 그런 점에서, 물체가 얼마나 멀리 떨어져 있는 지를 직관적으로 인식할 수 있게 된다.

### VR 최적화 이슈

> VR 애플리케이션을 만들때는 일반적인 애플리케이션보다 렌더링 비용이 더 많이 든다.

> 내부적으로는 카메라가 두개가 있기 때문에, 카메라가 한개인 일반적인 애플리케이션 보다 렌더링에 더 많은 비용을 요한다.

## AR 광학 / VR 광학

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/61a497d0-3051-499d-95c0-1204638ae9bb)
사람의 눈은 물체에 대해 초점을 맞출 수 있는 거리에 한계가 존재한다.

> _너무 가까운 물체는 초점을 맞출 수 없다._

이로 인해, 디스플레이를 눈으로부터 떨어트려야 하는데, 그럼에도 이는 여전히 가까이 있게 된다.

그 때문에, 렌즈를 활용해 눈이 초점을 맞출 수 있는 물리적 거리를 좁히는 방식을 사용한다.

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/0cb1ee61-e4e4-440e-81e3-921920d3d2c7)
렌즈로 인해, 이미지의 왜곡이 발생한다.

우측 상단의 이미지와 같이 물체를 평평한 사각형으로 렌더링하면, 좌측 상단의 이미지와 같이 왜곡되어 보인다. 그래서 이를 감안하여, 우측 하단과 같이 왜곡된 이미지를 렌더링함으로써, 우리 눈에 물체를 평평하게 보이게끔 한다.

지금 이러한 기술들은 SDK 내부에서 다 지원하기 때문에, 이러한 기술이 있다는 정도만 알아두는 정도로도 충분 할 것이다.

![Screen-door_effect](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/08227e8b-df87-49e2-aef2-1d41f76d2881)
이 과정에서 Screen Door Effect라고 하는, 해상도와 관련한 문제가 발생한다.

디스플레이를 눈 가까이에 두고 렌즈를 통해 디스플레이를 봄으로 인해 발생하며, 위 사진과 같이 각각의 화소가 구별될 정도로 뚜렷한 격자가 보인다.

이러한 효과는 사용자의 VR 경험에 부정적인 영향을 준다.

## 디스플레이 (LCD, LED, OLED)
### AMOLED
- Active Matrix Organic Light Emitting Diodes
- 유기 물질을 사용하여 빛을 내는 화소를 구동하는 디스플레이 기술
- OLED(유기 발광 다이오드) 기반의 한 형태
- Active Matrix 기술을 사용하여 각각의 화소를 더 정밀하게 제어한다.
- **빠른 반응 속도**와 **높은 해상도**를 달성할 수 있어, 
	  AMOLED 디스플레이는 비디오 재생이나 고속 움직임이 있는 게임에 적합한 선택이 된다.
- AMOLED 디스플레이는 화면 번인(screen burn-in)이라는 문제에 취약. 
	- 화면 번인(screen burn-in) : 
		디스플레이의 일부 화소가 과도하게 사용되어 시간이 지남에 따라 해당 화소의 색상이 영구적으로 변하는 현상
	
### Retina Display
- Active Matrix Liquid Crystal Display
- Apple Inc.가 자사의 일부 제품에 사용하는 마케팅 용어
- 사용자가 일반적인 시청 거리에서 화면의 개별 픽셀을 구분할 수 없을 정도로 높은 픽셀 밀도를 가진 디스플레이를 의미
- 2010년 iPhone 4와 함께 처음 소개되어, 이후 다양한 Apple사의 제품에 적용된 기술.
- 핵심 아이디어는 디스플레이의 픽셀 밀도를 사용자의 눈이 픽셀을 개별적으로 식별할 수 없는 수준까지 높임으로써, 텍스트와 이미지를 매우 선명하게 표현하는 것
- 픽셀 밀도는 제품에 따라 다르지만, 일반적으로 300ppi(pixels per inch) 이상

두 기술 모두 각각의 장단점이 있기 때문에, 여전히 이 대립구도는 유지되고 있음.

## LCD vs OLED
![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/b769b2a8-8af2-4345-8db2-382251d8b620)
### LCD
- 백라이트(BLU)가 존재
- 그 앞에 편광판 (POL).
- 그 앞에 TFT (Thin Film Transistor)가 존재. 이것이 Active Matrix라고 불리는 이유가 된다.
	- 화소 별 트랜지스터가 있어서, 화소 각각을 개별로 조작할 수 있게 한다.
	- Active Matrix가 아닌 방식은, 전자 계산기와 같은 방식
		![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/50f9901d-af84-4df4-968e-c2d55624cdc2)
		- 화소를 사용하지 않고, 화면을 이루는 각각의 부품에 개별로 전기신호를 통해 화면을 조작하는 방식.
- 중간에 위치한 Cell들을 전기신호로 조작하여 ColorFilter의 RGB 일부를 선택적으로 밝혀 화면을 구성한다. 
- 두번째 편광판(POL)는 ColorFilter의 RGB를 걸러내는 역할을 한다.

LCD 방식은 백라이트에서 나온 빛이 결과적으로 디스플레이되기까지 많은 과정을 거친다. 동일하게 많은 레이어를 지나오는 만큼, 다양한 부품이 필요하다. 그래서 경량화하기 어려운 구조.

### OLED
- 자체발광이라고 표현하기도 한다.
- 백라이트(BLU)를 사용해 화소를 밝히는 LCD와는 달리, 
	TFT & OLED 라는 하나의 레이어로 화소를 밝힐 수 있다.
- OLED의 편광판(POL)은 LCD의 편광판과는 목적이 다르다.
	자체 발광하는 OLED 특성상, 밝은 곳에서 화면 반사가 많은데, 이를 줄이기 위해서 존재한다.
- **[장점]**
	- **높은 명암비**
		LCD의 경우에는 백라이트를 사용함으로 인해, 완전한 Black을 표현하기 어렵지만, OLED는 자체 발광 방식을 사용하여 이론상 완전한 Black을 표현할 수 있다.
	- **높은 응답속도**
		빛이 화면의 표면에 닿아 표현되기까지 과정이 많고 복잡한 LCD에 비해, OLED는 각 픽셀이 직접 전류로 제어되어 자체적으로 빛을 발산하기 때문에, 높은 응답속도를 갖는다.
- **[단점]**
	- **번인 (Burn-in) 효과**
		장시간 같은 화면을 켜두거나, 혹은 채널마다 위치가 고정된 방송사 이미지가 화면에 계속 노출되면 그 부분의 색상이 제대로 표현되지 않거나 화면에 잔상(얼룩)이 영구적으로 남는 것
	- **밝기 부족**
		각 픽셀이 자체 발광방식을 사용함으로 인해 밝기 한계가 다른 방식에 비해 낮다.
	
LCD와 비교했을 때, 단순한 구조를 갖고있어 더 얇은 기기에 적용될 수 있는 구조. 

### LED
![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/cba4a90c-fd9f-47d9-8028-80800a19db2d)
- 위 모든 단점을 상회하는 LED (Light Emitting Diode)가 존재.
- **소형화가 힘들다**는 단점이 명확함.
- 지금도 이를 소형화하는 기술이 개발되고 있지만, 비교적 현재 기술력으로는 한 화소의 최소 크기가 비교적으로 크다.
- 따라서 VR에서 사용하기에는 적합하지 않은 방식.

### OLEDoS
![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/a2e170ad-26e9-480c-91e6-e7ccfa1bbed6)
- OLED on Silicon, Micro on OLED
- OLED 디스플레이를 실리콘 기판 위에 직접 통합시키는 방식.
- 픽셀의 밀도가 매우 높아지는 방식. 고 해상도.
- 비교적 장비를 더 가볍게 만들 수 있는 방식.
- VR에 쓰기 적합.
- 그러나, 다른 방식에 비해 제작에 높은 비용을 요한다.

## 깊이 인식 방식

### 방식 1. 카메라

- 둘 이상의 카메라를 활용해 깊이와 공간을 인식하는 방식
- 연산량이 늘어나는 이슈가 존재.
- 순간적으로 밝아지는 환경에서도 정밀도가 떨어지는 경향이 존재.

### 방식 2. IR
- Infrared Radiation, 직역하면 적외선 방사
- 높은 정밀도와 빠른 응답시간을 제공.
- 강한 태양광이나 IR 방식을 사용하는 또 다른 기기에 의한 간섭에 영향을 받을 수 있음.
- 사용자 주변 환경의 3D 맵을 생성하고, 이렇게 획득한 정보를 활용해 실제 세계와 상호작용하는 기능을 구현할 수 있도록 함.

### 방식 3. LiDAR
- Light Detection and Ranging
- 빛을 이용해 거리를 측정하고, 그 정보에 기반해 3D 모델을 생성하는 기술.
- 레이저 펄스를 대상에 발사하고, 반사된 빛이 돌아오는 시간을 측정해 거리를 계산.
- 유니티의 Raycast와 유사한 방식
- 매우 정밀한 측정이 가능해, 고해상도 3D 모델 생성 가능.
- 밀도가 높은 식생이나 어두운 환경에서도 사용 가능.
- 그러나 다른 방식에 비해 구현과 유지에 비용이 높은 방식.

## 디지털 멀미의 원인과 해결 방안

### 감각불일치

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/cff1eaf8-185e-4f79-87d2-0eab047b48b9)

VR에서 느끼는 멀미는 바로 이 경우에 해당한다.
우리 뇌에서는 다양한 감각을 통해 환경에 대한 정보를 인식한다. 시각, 촉각, 후각, 청각 등등...
VR 환경에서 우리가 느끼는 멀미를 감각불일치설에서는 가령 이런식으로 설명한다.
가상공간에서 컨트롤러를 통해 움직일 때, 눈으로는 우리가 움직인다고 인식하지만, 실제 몸은 가만히 의자에 앉아있다면 눈과 눈을 제외한 다른 감각은 각기 다른 정보를 뇌에 전달한다. 이렇게 뇌에서 모인 정보가 서로 상이한 정보를 담고 있기 때문에, 뇌에서는 이를 혼란스러워하고, 결국 멀미를 일으킨다고 설명한다.

물론 게임마다, 그리고 개인마다 정도의 차이가 있겠지만 보통 FPS 장르의 게임을 할 때 소위 3D 멀미라고 부르는 것이 바로 이 현상이다. 주위 사례들에 미루어보면, 나는 3D 멀미를 잘 못 느끼는 편 같다.

VR 애플리케이션을 만들 때는 이러한 사실에 대해 인지하고, 잘 고려해야 한다. 최대한 모든 감각이 동일한 정보, 혹은 유사한 정보를 인식하도록 해야한다. 혹은 그 차이를 줄이는 방향도 멀미를 줄이는 데에는 효과가 있을 것이다.

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/e21f5aea-aa77-4788-a259-f31b0c785a3f)
VR 애플리케이션 내에서 만약에 이동을 구현한다고 하면, 이동의 방식에 대해 고려해야 할 텐데, 여기에는 텔레포트 방식을 추천한다.

 그 이유는 일단 첫번째로 나의 경험을 들 수 있겠다. 
최근 VR 애플리케이션 개발 프로젝트를 진행하고 있다. 이 프로젝트에는 가상 공간에서 이동을 구현해야 했는데, 실제로 두가지 방식을 모두 직접 경험해 본 결과, 텔레포트 방식이 더 좋다라는 느낌을 확 체감했다. 앞서 언급했듯, 본인은 살면서 적어도 컴퓨터 모니터로는 3D 멀미를 전혀 느껴보지 못하는 정도이다. 그러나 얼마전 VR 장비를 쓰고 의자에 앉아 왼손 컨트롤러로 조이스틱을 주욱 미는 순간, 살아생전 가장 큰 3D 멀미를 체감했다. 너무 심했어서 당시에는 그냥 눈을 감아버렸다.

 그런 경험을 하고 나서는 누군가 VR 개발을 한다고 말한다면, 무조건 텔레포트 기능을 넣어라고 말할 정도로 이를 고려할 것을 권장한다. 

 위 영상에서도 이동에 대해서 언급하면서 가속운동과 등속운동을 구분했는데, 이 또한 매우 공감하는 바이다. 어쩔 수 없이 텔레포트를 사용하지 않고 직접 움직이도록 해야 한다면, 가속 운동이 아닌 등속 운동을 하도록 해야 한다. 가속 운동은 멀미를 매우매우 유발한다. 물론 이것도 나의 경험에 근거한 주장이다.

 위 영상에서는 Snap Turn, 그러니까 시야를 회전하는 방식에 대해서도 언급한다. 일반적인 PC 3D 게임, FPS 장르의 게임을 보면 마우스를 따라 시야의 방향이 부드럽게 변한다. 이러한 방식은 VR에서 매우 좋지 않다. 이 또한 멀미를 유발한다, 이 또한 본인의 경험에 강하게 그 근거를 두고 있다. 그래서 Snap Turn, 조이스틱과 같은 입력을 통해 시야를 뚝뚝 끊어 회전하는 방식은 오히려 멀미를 줄이는 데 더 도움이 되는 방식이라고 생각한다.


 VR과 관련한 전문적인, 광학과 관련한 전문성이 전혀 없는 사람으로써의 주장이지만, 아무래도 이러한 멀미 유발 현상의 원인은 장비의 성능에 있지 않을까 생각한다. 기본적으로 현재 VR에 사용되는 디스플레이의 해상도는, 사람의 눈이 현실을 인식하는 해상도에 여전히 못 미치며, 매 프레임마다 새로운 영상을 안정적으로 화면에 띄울 수 있는 연산능력 또한 아직 받쳐주지 못해서 그런게 아닐까 싶다. 


 개인적인 주장은 여기까지 하고, 그래서 위 영상에서는 "따뜻한 아이스 아메리카노"와 같다고 표현했는데, 멀미를 줄이기 위해서는 어쩔 수 없이 몰입도를 의도적으로 깨야한다는 말을 한다. 이 부분에 대해서는 깊게 동감한다. 그래서 그 적절한 선을 잘 찾아 연하는 것이 VR 개발자의 숙제라고 생각한다.

 그리고 위 영상에서 설명하듯, 컷씬에서 Camera를 활용하는 건 지양해야 한다. 그런 맥락에서 Cinemachine은 사용하지 말 것. 그냥 카메라는 건드리지 마라! 정도로 알아두면 될 것 같다.

### VR 최적화
위 영상에서는 멀미를 최소화하는 방법으로 최적화를 언급한다. 나도 동감하는 바이다. 고개를 돌려 시야의 방향이 변하는데, 최적화가 부족해서 프레임이 끊기면서 화면이 뒤늦게 따라온다면, 그것 또한 멀미를 유발할 것이다. 그래서 VR 개발을 진행중이라면, 최적화는 꼭 놓치지 말자. 관련 문서도 찾아보면 좋을 것이다. Unity에서는 관련해서 E-Book도 제공한다, 저번에 찾기로는 오직 최적화만을 주제로 매우 큰 분량의 E-Book을 스치듯 본 적이 있는데, 다시 한번 정독해봐야겠다.

### Screen Overlay UI
UI는 Screen Overlay로 띄우지 말 것. World Space로 띄워야 한다. 왜인지는 직접 써보면 알 것이다. 매우 어색하게 연출된다. 그래서

### 3D UI
3D로 UI를 World Space에 오브젝트처럼 배치하는 것이 권장된다. 위 영상에서는 모범적인 사례로 데드스페이스를 언급하는데, 본인도 최근에 즐겨본 사람으로서 동감하는 바이다. 데드스페이스의 UI는 타 게임에 비해 특이한 점이 있다. TPS, 3인칭 슈터 게임이라 주인공 캐릭터의 등 뒤에서 카메라가 주인공이 보는 방향을 비추는데, 주인공의 등을 활용해 여기에 체력바와 스킬과 관련한 UI를 배치했다. 공격받으면 이 체력바가 한칸씩 줄어들고, 스킬도 사용하면 한칸씩 줄어든다. 상당히 인상적인 방식이다. 

### Vergence Accommodation Conflict

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/f4f44864-5fee-4234-801c-a5ea0ff13581)

우리가 VR을 착용하는 상황을 생각해보면, 디스플레이는 우리 눈 바로 앞에 위치하지만 우리 눈이 초점은 저 멀리에 있는 물체에 대해 맺힌다. 이 상황이 위 그림의 우측에서 묘사되어 있다. 

Distance of accommodation과 Distance of vergence가 차이나는 것이 바로 그 것이다.

이 또한 멀미를 유발하는 요인이 된다. 이를 완벽히 보완하는 것은 불가능에 가깝겠지만, 어느정도 이를 고려해서 멀미가 적도록 해야한다. 위 영상에서 설명하듯, 움직이는 물체의 속도는 너무 빠르지 않도록 해야하고, 가까운 것보다는 차라리 멀리 배치하는 것이 좋다고 한다. 나와의 거리가 급격하게 변하는 상황도 최대한 피해야 한다.

### 양안경합 / 망막경합

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/55e2d721-2c06-4a2b-9eff-5d4eb488285c)

이는 위 사진과 같이 한쪽 눈으로는 보이는 물체가, 다른 쪽 눈으로는 보이지 않는, 그런 상황을 묘사했다. 그런데 사실 이런 현상은 의도하지 않는 한 일어나기 힘들겠지만, 

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/368cb5e8-fe37-408c-b82b-e89699bbbb31)

이렇게, 물체 표면의 Specular(경면광) 효과에 대해서는 적지않게 발생할 수 있겠다. 이는 위와 같이 금속 재질의 표면을 표현할 때, 그 특성상 경면광이 강하게 적용되기 때문에 발생하는것도 원인이겠다. 그리고 당연히, 두 카메라의 위치가 동일하지 않기 때문에 발생하기도 하겠다. 그래서 이러한 맥락에서는 VR 애플리케이션에서 금속 재질의 물체를 렌더링하는 걸 피하고, 만약 사용하더라도 경면광이 강하게 적용되는 걸 피하는 것이 좋겠다.

이것이 실사기반 그래픽보다 카툰풍의 그래픽이 VR 애플리케이션에서 더 많이 사용되는 이유 중 하나가 되는 것 같기도 하다.

### Convergence Insuffuciency 수렴 부족

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/7369cc10-9535-4d46-80bf-997d11af6707)

앞서 언급한 것 처럼 너무 가까운 물체에 대해서는 초점을 맞추기 힘든데, 위 사진과 같이 FPS 장르의 게임이라면 그 특성상 조준경이 눈 가까이 표현되는건 오랫동안 이어져 온 장르상의 특징이다. 이렇게 되면, 실제로 한쪽 눈을 감아야 초점을 맞출 수 있다고 한다. 실제 총을 쏘듯.

그래서 이렇게 화면 가까이 물체를 배치하는 것은 지양하는 걸 고려한다.

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/4395385f-c7df-4a48-bde3-ee559b2c3751)

같은 맥락에서 FPS 게임이라면, Hand Scaling 방식을 사용한다고 한다. Hand Scaling 방식이란 실제로는 손에 쥔 총을 매우 작게 만들어 카메라에 가까이 붙이는 것이라고 한다.
이렇게 하는 이유로는 총이 원래 크기처럼 어색하지 않게 표현되면서, 벽에 가까이 가도 총이 파뭍히지 않도록 할 수 있기 때문이라고 한다.

그러나, 이러한 Hand Scaling은 일반적인 평면 모니터상에서만 사용가능한 기법이고, VR에서 똑같이 해버리면, 총이 그대로 작게 표현된다. 그래서 이러한 방식을 VR에도 그대로 가져오는 건 피해야 한다.

![image](https://github.com/BJH7536/BJH7536.github.io/assets/114412598/318e7a88-41e8-49c4-9175-73b7b39a2fb1)

위 영상에서 Billboard라는 단어를 처음 접해서 이를 알아보았다. 사실 내가 여태까지 다양한 게임을 접하면서 이미 접한 개념인데, 이를 조사해보면 보통 다음과 같이 설명한다.

> 3D 환경 내에서 항상 카메라를 향해 정면을 유지하는 2D 객체

이 설명을 보자마자 다양한 게임에서 접한 파티클이라던지, 나무의 나뭇잎들, 뭐 그런것들이 머릿속에 스쳐지나갔다. 보면서, 아 게임 리소스 줄이고 최적화를 위해 이렇게 했겠거니 싶었는데, 이를 지칭하는 이름이 Billboard라는 것은 이번에 처음 알았다.

아무튼, 그래서 위 영상에서는 이러한 Billboard가 VR에서는 현실감을 방해하는 요소가 된다고 한다. 확실히, 여기까지 봤을 때 여러 VR 애플리케이션이 다들 카툰 스타일의 그래픽으로 가는 이유를 알겠다.
